# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fGnrJGJHZ9i4wz4M9cei3urfowux2Mmy
"""

# Lab Test  
# 02190150
# Pema Wangyal Dorji
# CST

"""Importing the necessary libraries and packages."""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense, Bidirectional, Dropout

"""Loading the required dataset using pandasâ€™s read excel function."""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_excel('/content/drive/MyDrive/AI/CSTData.xlsx')

"""Running the df.head() function to return the first 5 observations."""

df.head()

"""The df.shape prints out the records and fields respectively"""

print(df.shape)

"""Describe() function in pandas helps to view various statistical summary."""

df.describe()

"""**DATA PREPROCESSING**

Dropping the Tuples Game Number and Date as they are not needed.
"""

df.drop(['Game Number', 'Date'], axis=1, inplace=True)

df.head()

"""Deep learning algorithms anticipate that all input features will vary similarly, with a mean and variance of ideally 0. and 1. Our data must be rescaled in order to meet these specifications."""

scaler = StandardScaler().fit(df.values)
transformed_dataset = scaler.transform(df.values)
transformed_df = pd.DataFrame(data=transformed_dataset, index=df.index)

transformed_df.head()

"""Defining the Variables"""

# All our games
number_of_rows = df.values.shape[0]
number_of_rows

# Amount of games we need to take into consideration for prediction
window_length = 7
window_length

# Balls counts
number_of_features = df.values.shape[1]
number_of_features

"""Creating X and Y for each row in our scaled data."""

X = np.empty([ number_of_rows - window_length, window_length, number_of_features], dtype=float)
y = np.empty([ number_of_rows - window_length, number_of_features], dtype=float)
for i in range(0, number_of_rows-window_length):
    X[i] = transformed_df.iloc[i : i+window_length, 0 : number_of_features]
    y[i] = transformed_df.iloc[i+window_length : i+window_length+1, 0 : number_of_features]

"""**MODELLING**

Initializing the RNN.

Adding the input layer and the LSTM layer.

Adding dropout() layer to reduce overfitting.
"""

model = Sequential()
model.add(Bidirectional(LSTM(240, input_shape = (window_length, number_of_features), return_sequences = True)))
model.add(Dropout(0.2))
model.add(Bidirectional(LSTM(240, input_shape = (window_length, number_of_features), return_sequences = True)))
model.add(Dropout(0.2))
model.add(Bidirectional(LSTM(240, input_shape = (window_length, number_of_features), return_sequences = True)))
model.add(Bidirectional(LSTM(240, input_shape = (window_length, number_of_features), return_sequences = False)))
model.add(Dense(59))
model.add(Dense(number_of_features))

"""Compiling the RNN"""

from tensorflow import keras
from tensorflow.keras.optimizers import Adam
model.compile(optimizer=Adam(learning_rate=0.0001), loss ='mse', metrics=['accuracy'])

"""**MODEL TRAINING**"""

model.fit(x=X, y=y, batch_size=15, epochs=200, verbose=2)

"""**ANALYSING RESULTS**"""

to_predict = df.tail(7)
to_predict

to_predict.drop([to_predict.index[-1]],axis=0, inplace=True)
to_predict

to_predict = np.array(to_predict)
to_predict

scaled_to_predict = scaler.transform(to_predict)
scaled_to_predict

y_pred = model.predict(np.array([scaled_to_predict]))
print("The predicted numbers for the next lottery game are:", scaler.inverse_transform(y_pred).astype(int)[0])

"""**RESULTS**

The results obtained after training this model using the LSTM Model is:  
 [32  9 21  9  14  21]
"""